{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef1db504-aad4-41f1-b87c-7372f41cd18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as torchF\n",
    "import pandas as pd\n",
    "import idx2numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a993907d-8b55-4f2a-b54f-ef0429bd8ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 7x12 bitmapped images to train LeNet against\n",
    "from bitstring import BitArray\n",
    "\n",
    "def bitstring_to_pbm(bitstring_data, width, height, filename):\n",
    "    \"\"\"\n",
    "    Converts a bitstring to a PBM image file.\n",
    "\n",
    "    Args:\n",
    "        bitstring_data: A bitstring object containing the image data.\n",
    "        width: The width of the image in pixels.\n",
    "        height: The height of the image in pixels.\n",
    "        filename: The name of the PBM file to create.\n",
    "    \"\"\"\n",
    "    if len(bitstring_data) != width * height:\n",
    "        raise ValueError(\"Bitstring length does not match image dimensions.\")\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"P1\\n\")  # PBM format header (ASCII)\n",
    "        f.write(f\"{width} {height}\\n\")  # Image dimensions\n",
    "\n",
    "        # Write pixel data (1 for black, 0 for white)\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                f.write(str(int(bitstring_data[i * width + j])) + \" \")\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04adcaf3-b76a-4826-9615-272add294228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need ascii 32 to 126\n",
    "filename='ASCII_pbms/ASCII_126.pbm'\n",
    "data = '''\n",
    "0000000\n",
    "0000000\n",
    "0000000\n",
    "0000000\n",
    "0000000\n",
    "0001001\n",
    "0110110\n",
    "0000000\n",
    "0000000\n",
    "0000000\n",
    "0000000\n",
    "0000000\n",
    "'''\n",
    "\n",
    "width = 7\n",
    "height = 12\n",
    "image_data = np.array(list(data.replace('\\n', ''))).reshape(height, width).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e417f1-8461-423d-8180-c82d5872f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image using imshow\n",
    "plt.imshow(image_data, cmap='gray_r')\n",
    "ax = plt.gca()\n",
    "\n",
    "# Set border properties\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_edgecolor('grey')  # Set border color\n",
    "    spine.set_linewidth(2)      # Set border thickness\n",
    "\n",
    "# Remove the ticks\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5660b53d-a4ae-481e-874e-7be3e7e8e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save image\n",
    "\n",
    "data = BitArray(bin=data)\n",
    "\n",
    "#check for file\n",
    "if filename.split('/')[1] not in os.listdir('ASCII_pbms'):\n",
    "    print('creating file', filename)\n",
    "    bitstring_to_pbm(data, width, height, filename)\n",
    "else:\n",
    "    print('file already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b754154-4691-46a9-8bad-4613da10ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print PBM images\n",
    "def read_pbm_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        l = f.readlines()\n",
    "    bits = []\n",
    "    for i in range(2, len(l)):\n",
    "        lstr = l[i].replace('\\n', '').replace(' ', '')\n",
    "        bits.append([int(b) for b in lstr])\n",
    "\n",
    "    bits = np.array(bits)\n",
    "    return bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642160d4-50ea-4fea-8397-268105613b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'ASCII_pbms/ASCII_54.pbm'\n",
    "image_data = read_pbm(filename)\n",
    "\n",
    "# Display the image using imshow\n",
    "plt.imshow(image_data, cmap='gray_r')\n",
    "ax = plt.gca()\n",
    "\n",
    "# Set border properties\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_edgecolor('grey')  # Set border color\n",
    "    spine.set_linewidth(2)      # Set border thickness\n",
    "\n",
    "# Remove the ticks\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2c4ddb-c06e-407a-af62-793619b94a3c",
   "metadata": {},
   "source": [
    "## Training MNIST Against 7x12 Bitmapped ASCII Printable Chars\n",
    "\n",
    "In the LeNet paper, loss function is a Euclidean RBF comparison of output layer against an \"idealized\" version of the inputs (7x12 bitmapped ASCII). I couldn't find a dataset for these online, so I recreated them. The section below recreates the single-char classification model from the first half of the LeNet paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b65af4-2243-4b12-8efd-47cca6bafaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset prep\n",
    "ascii_map = open('emnist/emnist-byclass-mapping.txt', 'r').readlines()\n",
    "ascii_map = dict([(int(l.rstrip().split(' ')[0]), int(l.rstrip().split(' ')[1])) for l in ascii_map])\n",
    "\n",
    "col_names = ['class'] + ['pix'+str(i) for i in range(28*28)]\n",
    "df_train = pd.read_csv('emnist/emnist-byclass-train.csv', names=col_names)\n",
    "df_train['ascii#'] = df_train['class'].map(ascii_map)\n",
    "df_test = pd.read_csv('emnist/emnist-byclass-test.csv', names=col_names)\n",
    "df_test['ascii#'] = df_test['class'].map(ascii_map)\n",
    "\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d92a4b-b60d-429f-9748-b41b460bf221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_img(df, idx):\n",
    "    a = df_test.iloc[idx, 1:-1].to_numpy().reshape(28, 28).T\n",
    "    print(df_test.iloc[idx, -1])\n",
    "    plt.imshow(a, cmap='gray_r')\n",
    "\n",
    "print_img(df_train, 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc454e9-798d-40dd-a30c-dfe58898ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load full printable ascii bitmap set into \"parameter\" tensor for model eval\n",
    "bm_l = []\n",
    "bm_dict = {}\n",
    "for i, num in enumerate(sorted(pd.concat([df_test['ascii#'], df_train['ascii#']]).unique().tolist())):\n",
    "    fname = f'ASCII_pbms/ASCII_{num}.pbm'\n",
    "    arr = read_pbm_file(fname)\n",
    "    bm_l.append(arr)\n",
    "    bm_dict[num] = i\n",
    "\n",
    "bm_param = torch.Tensor(np.array(bm_l)).reshape(62, 84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ff670-74ee-4971-8d8e-9d1bf22b617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#init hyperparams and weights\n",
    "#hyperparams\n",
    "F = 5 #size of square conv kernel\n",
    "S = 1 #stride of conv kernel\n",
    "B = 64 #batch dimension\n",
    "SS = 2 #subsampling window size\n",
    "act_list = {}\n",
    "\n",
    "#weights\n",
    "W1 = torch.randn((6, 1, 1, F, F)) / (F*F)\n",
    "b1 = torch.randn((6, 1, 1))\n",
    "w2 = torch.randn((6, 1, 1))\n",
    "b2 = torch.randn((6, 1, 1))\n",
    "W3_sparse_conv_idx = sum([[(i+x) % 6 for x in range(3)] for i in range(6)], [])\n",
    "W3_sparse_conv_idx += sum([[(i+x) % 6 for x in range(4)] for i in range(6)], [])\n",
    "W3_sparse_conv_idx += [0, 1, 3, 4, 1, 2, 4, 5, 0, 2, 3, 5] + list(range(6))\n",
    "W3 = torch.randn((60, 1, 1, F, F)) / (F*F*60)\n",
    "b3 = torch.randn((16, 1, 1))\n",
    "w4 = torch.randn((16, 1, 1))\n",
    "b4 = torch.randn((16, 1, 1))\n",
    "W5 = torch.randn((120, 16, 5, 5)) / (F*F*16)\n",
    "b5 = torch.randn(120)\n",
    "W6 = torch.randn((120, 84)) / 120**0.5\n",
    "b6 = torch.randn(84)\n",
    "\n",
    "params = [W1, b1, w2, b2, W3, b3, w4, b4, W5, b5, W6, b6]\n",
    "for p in params:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02f3bc4-6fec-4ba6-b75a-099672c9c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "iters = 10000\n",
    "losses = []\n",
    "B = 32\n",
    "\n",
    "for i in range(iters):\n",
    "    \n",
    "    #feedforward\n",
    "    #retrieve sample batch, convert to numpy\n",
    "    x_batch = df_train.sample(B).iloc[:, 1:].to_numpy()\n",
    "    x, y = x_batch[:, :-1], x_batch[:, -1]\n",
    "    \n",
    "    #reshape to square matrix and zero pad 2-pixels on each side: (28x28) --> (32x32)\n",
    "    x = x.reshape(B, 28, 28)\n",
    "    x = torch.transpose(torch.Tensor(x), 1, 2)\n",
    "    x = torchF.pad(x, pad=(2, 2, 2, 2), value=0.0)\n",
    "    \n",
    "    #normalize\n",
    "    x = x / 255.0\n",
    "    act_list['xin'] = x\n",
    "    \n",
    "    #convolution1\n",
    "    x_conv1 = x.unfold(1, F, S).unfold(2, F, S).unsqueeze(1)\n",
    "    x = (x_conv1 * W1).sum(dim=(-2, -1)) + b1\n",
    "    #insert normalization here\n",
    "    act_list['conv1'] = x\n",
    "    x = x.sigmoid()\n",
    "    \n",
    "    #subsampling2\n",
    "    x = x.unfold(2, SS, SS).unfold(3, SS, SS).sum(dim=(-2, -1))\n",
    "    x /= float(SS*SS)\n",
    "    x = x * w2 + b2\n",
    "    act_list['ss2'] = x\n",
    "    x = x.sigmoid()\n",
    "    \n",
    "    #conv3, uses special sparse connections\n",
    "    #define sparse convolutional connections\n",
    "    \n",
    "    #applying sparse conv index, unfold into convs\n",
    "    x_conv3 = x[:, W3_sparse_conv_idx, :, :].unfold(2, F, S).unfold(3, F, S)\n",
    "    x = (x_conv3 * W3).sum(dim=(-2, -1))\n",
    "    #sum together 60 convs into 16 feature maps\n",
    "    W3_sparse_summed = [x[:, 3*i:3*(i+1), :, :].sum(dim=1, keepdim=True) for i in range(6)] \n",
    "    W3_sparse_summed += [x[:, 18+4*i:18+4*(i+1), :, :].sum(dim=1, keepdim=True) for i in range(9)]\n",
    "    W3_sparse_summed += [x[:, 54:60, :, :].sum(dim=1, keepdim=True)]\n",
    "    \n",
    "    x = torch.cat(W3_sparse_summed, dim=1)\n",
    "    x += b3\n",
    "    act_list['conv3'] = x\n",
    "    x = x.sigmoid()\n",
    "    \n",
    "    #subsamp4\n",
    "    x = x.unfold(2, SS, SS).unfold(3, SS, SS).sum(dim=(-2, -1))\n",
    "    x /= float(SS*SS)\n",
    "    x = x * w4 + b4\n",
    "    act_list['ss4'] = x\n",
    "    \n",
    "    #conv5\n",
    "    x = (x.unsqueeze(1) * W5).sum(dim=(-3, -2, -1)) + b5\n",
    "    act_list['conv5'] = x\n",
    "    x = x.sigmoid()\n",
    "    \n",
    "    #F6, fully connected\n",
    "    x = x @ W6 + b6\n",
    "    act_list['f6'] = x\n",
    "    x = torchF.tanh(x) #tanh in paper instead of sigmoid like other layers\n",
    "    \n",
    "    #O7, output layer\n",
    "    x = (x.unsqueeze(-1) - bm_param.T).square().sum(dim=1)\n",
    "    x /= 84.0\n",
    "    act_list['out7'] = x.reshape(-1)\n",
    "    \n",
    "    #backpropagation\n",
    "    \n",
    "    #loss function\n",
    "    #get index of y_pred value\n",
    "    y_idx = np.vectorize(lambda x: bm_dict[x])(y)\n",
    "    loss = (x[np.arange(x.shape[0]), y_idx] + (x*-1).exp().sum(axis=1).log()).mean()\n",
    "\n",
    "    assert 1 == 2\n",
    "    \n",
    "    #backprop/gradient update\n",
    "    loss.backward()\n",
    "    if i % 500 == 0:\n",
    "        losses.append(loss.item())\n",
    "        print('loss:', loss.item())\n",
    "    lr = 0.1\n",
    "    for p in params:\n",
    "        p.data += -lr * p.grad\n",
    "        p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a66882d-4b0b-4805-b2d3-3f628a54b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feedforward\n",
    "#retrieve sample batch, convert to numpy\n",
    "x_batch = df_train.sample(B).iloc[:, 1:].to_numpy()\n",
    "x, y = x_batch[:, :-1], x_batch[:, -1]\n",
    "\n",
    "#reshape to square matrix and zero pad 2-pixels on each side: (28x28) --> (32x32)\n",
    "x = x.reshape(B, 28, 28)\n",
    "x = torch.transpose(torch.Tensor(x), 1, 2)\n",
    "x = torchF.pad(x, pad=(2, 2, 2, 2), value=0.0)\n",
    "\n",
    "#normalize\n",
    "x = x / 255.0\n",
    "act_list['xin'] = x\n",
    "\n",
    "#convolution1\n",
    "x_conv1 = x.unfold(1, F, S).unfold(2, F, S).unsqueeze(1)\n",
    "x = (x_conv1 * W1).sum(dim=(-2, -1)) + b1\n",
    "#insert normalization here\n",
    "act_list['conv1'] = x\n",
    "x = x.sigmoid()\n",
    "\n",
    "#subsampling2\n",
    "x = x.unfold(2, SS, SS).unfold(3, SS, SS).sum(dim=(-2, -1))\n",
    "x /= float(SS*SS)\n",
    "x = x * w2 + b2\n",
    "act_list['ss2'] = x\n",
    "\n",
    "#conv3, uses special sparse connections\n",
    "#define sparse convolutional connections\n",
    "\n",
    "#applying sparse conv index, unfold into convs\n",
    "x_conv3 = x[:, W3_sparse_conv_idx, :, :].unfold(2, F, S).unfold(3, F, S)\n",
    "x = (x_conv3 * W3).sum(dim=(-2, -1))\n",
    "#sum together 60 convs into 16 feature maps\n",
    "W3_sparse_summed = [x[:, 3*i:3*(i+1), :, :].sum(dim=1, keepdim=True) for i in range(6)] \n",
    "W3_sparse_summed += [x[:, 18+4*i:18+4*(i+1), :, :].sum(dim=1, keepdim=True) for i in range(9)]\n",
    "W3_sparse_summed += [x[:, 54:60, :, :].sum(dim=1, keepdim=True)]\n",
    "\n",
    "x = torch.cat(W3_sparse_summed, dim=1)\n",
    "x += b3\n",
    "act_list['conv3'] = x\n",
    "x = x.sigmoid()\n",
    "\n",
    "#subsamp4\n",
    "x = x.unfold(2, SS, SS).unfold(3, SS, SS).sum(dim=(-2, -1))\n",
    "x /= float(SS*SS)\n",
    "x = x * w4 + b4\n",
    "act_list['ss4'] = x\n",
    "\n",
    "#conv5\n",
    "x = (x.unsqueeze(1) * W5).sum(dim=(-3, -2, -1)) + b5\n",
    "act_list['conv5'] = x\n",
    "x = x.sigmoid()\n",
    "\n",
    "#F6, fully connected\n",
    "x = x @ W6 + b6\n",
    "act_list['f6'] = x\n",
    "x = torchF.tanh(x) #tanh in paper instead of sigmoid like other layers\n",
    "\n",
    "#O7, output layer\n",
    "x = (x.unsqueeze(-1) - bm_param.T).square().sum(dim=1)\n",
    "x /= 84.0\n",
    "act_list['out7'] = x\n",
    "\n",
    "#backpropagation\n",
    "\n",
    "#loss function\n",
    "#get index of y_pred value\n",
    "y_idx = np.vectorize(lambda x: bm_dict[x])(y)\n",
    "#loss = (x[np.arange(x.shape[0]), y_idx] + (x*-1).exp().sum(axis=1).log()).mean()\n",
    "loss = x[:, y_idx].mean()\n",
    "loss.backward()\n",
    "\n",
    "lr = 0.1\n",
    "for p in params:\n",
    "    p.data += -lr * p.grad\n",
    "    p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5796a3f-a354-4e40-9e8b-7e366a2eb9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: 0.34159621596336365\n",
      "iter 500: 0.17374785244464874\n",
      "iter 1000: 0.10848686099052429\n",
      "iter 1500: 0.09682769328355789\n",
      "iter 2000: 0.0939687192440033\n",
      "iter 2500: 0.07197171449661255\n",
      "iter 3000: 0.07175041735172272\n",
      "iter 3500: 0.07716022431850433\n",
      "iter 4000: 0.0811852365732193\n",
      "iter 4500: 0.07756172120571136\n",
      "iter 5000: 0.08283617347478867\n",
      "iter 5500: 0.07364185154438019\n",
      "iter 6000: 0.06847753375768661\n",
      "iter 6500: 0.06473362445831299\n",
      "iter 7000: 0.06389860063791275\n",
      "iter 7500: 0.06067684292793274\n",
      "iter 8000: 0.061996202915906906\n",
      "iter 8500: 0.06137581914663315\n",
      "iter 9000: 0.06210257112979889\n",
      "iter 9500: 0.05484551563858986\n"
     ]
    }
   ],
   "source": [
    "# Feedforward with fixes, helped by claude\n",
    "def forward(x_batch):\n",
    "    \n",
    "    # Retrieve sample batch, convert to numpy\n",
    "    x, y = x_batch[:, :-1], x_batch[:, -1]\n",
    "    \n",
    "    # Reshape to square matrix and zero pad 2-pixels on each side: (28x28) --> (32x32)\n",
    "    x = x.reshape(B, 28, 28)\n",
    "    x = torch.transpose(torch.Tensor(x), 1, 2)\n",
    "    x = torchF.pad(x, pad=(2, 2, 2, 2), value=0.0)\n",
    "    \n",
    "    # Normalize to [-0.1, 1.1] range as per paper\n",
    "    x = (x / 255.0) * 1.2 - 0.1\n",
    "    \n",
    "    # Convolution1\n",
    "    x_conv1 = x.unfold(1, F, S).unfold(2, F, S).unsqueeze(1)\n",
    "    x = (x_conv1 * W1).sum(dim=(-2, -1)) + b1\n",
    "    x = torch.sigmoid(x)  # Using torch.sigmoid for better gradient flow\n",
    "    \n",
    "    # Subsampling2\n",
    "    x = x.unfold(2, SS, SS).unfold(3, SS, SS).sum(dim=(-2, -1))\n",
    "    x /= float(SS*SS)\n",
    "    x = x * w2 + b2\n",
    "    x = torch.sigmoid(x)  # Add activation after subsampling\n",
    "    \n",
    "    # Conv3, uses special sparse connections\n",
    "    x_conv3 = x[:, W3_sparse_conv_idx, :, :].unfold(2, F, S).unfold(3, F, S)\n",
    "    x = (x_conv3 * W3).sum(dim=(-2, -1))\n",
    "    \n",
    "    # Sum together 60 convs into 16 feature maps\n",
    "    W3_sparse_summed = [x[:, 3*i:3*(i+1), :, :].sum(dim=1, keepdim=True) for i in range(6)] \n",
    "    W3_sparse_summed += [x[:, 18+4*i:18+4*(i+1), :, :].sum(dim=1, keepdim=True) for i in range(9)]\n",
    "    W3_sparse_summed += [x[:, 54:60, :, :].sum(dim=1, keepdim=True)]\n",
    "    x = torch.cat(W3_sparse_summed, dim=1)\n",
    "    x += b3\n",
    "    x = torch.sigmoid(x)\n",
    "    \n",
    "    # Subsamp4\n",
    "    x = x.unfold(2, SS, SS).unfold(3, SS, SS).sum(dim=(-2, -1))\n",
    "    x /= float(SS*SS)\n",
    "    x = x * w4 + b4\n",
    "    x = torch.sigmoid(x)  # Add activation after subsampling\n",
    "    \n",
    "    # Conv5\n",
    "    x = (x.unsqueeze(1) * W5).sum(dim=(-3, -2, -1)) + b5\n",
    "    x = torch.sigmoid(x)\n",
    "    \n",
    "    # F6, fully connected\n",
    "    x = x @ W6 + b6\n",
    "    x = torch.tanh(x)  # tanh in paper instead of sigmoid like other layers\n",
    "    \n",
    "    # O7, output layer - proper RBF implementation as in the paper\n",
    "    # Calculate Euclidean distance to each prototype\n",
    "    distances = (x.unsqueeze(-1) - bm_param.T).square().sum(dim=1)\n",
    "    # Apply Gaussian kernel (RBF)\n",
    "    outputs = torch.exp(-0.5 * distances / 84.0)  # The scaling factor is from the paper\n",
    "    \n",
    "    return outputs, y\n",
    "\n",
    "# Loss function for RBF network\n",
    "def compute_loss(outputs, y, bm_dict):\n",
    "    # Convert labels to indices\n",
    "    y_idx = np.vectorize(lambda x: bm_dict[x])(y)\n",
    "    \n",
    "    # Cross-entropy-like loss for RBF network\n",
    "    # We want to maximize the output for the correct class\n",
    "    correct_class_outputs = outputs[torch.arange(outputs.shape[0]), y_idx]\n",
    "    loss = -torch.log(correct_class_outputs + 1e-10).mean()  # Add small epsilon for numerical stability\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Training loop\n",
    "def train_step(x_batch, params, lr=0.01):\n",
    "    outputs, y = forward(x_batch)\n",
    "    loss = compute_loss(outputs, y, bm_dict)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Correct gradient update direction\n",
    "    for p in params:\n",
    "        p.data -= lr * p.grad  # Subtract, not add!\n",
    "        p.grad = None\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "def save_model(params):\n",
    "    for i, p in enumerate(params):\n",
    "        torch.save(p, f'model_artifacts/model_{i}')\n",
    "\n",
    "def restore_model(params):\n",
    "    for i in range(len(params)):\n",
    "        params[i] = torch.load(f'model_artifacts/model_{i}')\n",
    "\n",
    "\n",
    "losses = []\n",
    "B = x_batch.shape[0]\n",
    "F = 5  # Filter size\n",
    "S = 1  # Stride\n",
    "SS = 2  # Subsampling size\n",
    "for i in range (10000):\n",
    "    x_batch = df_train.sample(B).iloc[:, 1:].to_numpy()\n",
    "    l = train_step(x_batch, params)\n",
    "    if i % 500 == 0:\n",
    "        print(f'iter {i}:', l)\n",
    "    losses.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "824b6c3a-3c22-4c9e-9c4c-6210da149e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6be07-bf24-4c70-8fc5-5fed76e9153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:, 1:].to_numpy()\n",
    "x_test = df_test.iloc[:, 1:].to_numpy()\n",
    "outputs, y = forward(x_train)\n",
    "\n",
    "\n",
    "def compute_accuracy(outputs, y):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514821c0-bccc-4c3a-9556-7f199f7e278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize activations and gradients\n",
    "# Plotting multiple histograms\n",
    "for k in act_list.keys():\n",
    "    #plt.hist(act_list[k].reshape(-1), bins=30, alpha=0.7, label=f'act_list_{k}', histtype='step')\n",
    "    print(f'{k}: {act_list[k].mean()}, {act_list[k].var()}')\n",
    "    \n",
    "#plt.title('Activation distributions')\n",
    "#plt.legend(loc='upper right')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a76dea-9cbe-4da1-a3e7-c60d8b95298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variance in each sample in batch across layers\n",
    "for k in act_list.keys():\n",
    "    print(f'{k}: {act_list[k].var(axis=0).mean()}', act_list[k].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0885adb-c84e-4225-8894-b8323ad58025",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in params:\n",
    "    plt.hist(p.grad.reshape(-1), bins=30, alpha=0.7, label=f'act_list_{k}', histtype='step')\n",
    "    print(p.grad.mean(), p.grad.var())\n",
    "\n",
    "plt.title('gradient dists')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd80c476-e3d1-4806-b0a3-84c98f404607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07add2e5-1439-4f67-8977-f226d033d7e2",
   "metadata": {},
   "source": [
    "## Classification of entire sections of Handwriting\n",
    "\n",
    "after creating the simpler single-char predictor, LeNet specifies a graph structure for OCR on full sections of handwritten text. The creation of dataset and recreation of that model is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a84196",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#creation of handwritten text dataset\n",
    "splits = {'train': 'data/train.parquet', 'validation': 'data/validation.parquet', 'test': 'data/test.parquet'}\n",
    "df_train = pd.read_parquet(\"hf://datasets/Teklia/IAM-line/\" + splits[\"train\"])\n",
    "df_val = pd.read_parquet(\"hf://datasets/Teklia/IAM-line/\" + splits[\"validation\"])\n",
    "df_test = pd.read_parquet(\"hf://datasets/Teklia/IAM-line/\" + splits[\"test\"])\n",
    "\n",
    "#define types\n",
    "df_train['type'] = 'train'\n",
    "df_val['type'] = 'validation'\n",
    "df_test['type'] = 'test'\n",
    "\n",
    "\n",
    "#concat, isolate image bytestrings, save\n",
    "df = pd.concat([df_train, df_val, df_test])\n",
    "df['bytes'] = df.image.apply(lambda x: x['bytes'])\n",
    "df[['text', 'bytes', 'type']].to_parquet('df.parquet.gzip', compression='gzip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f10bb5-a3e0-4a26-a87f-08b761e66e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c558406-3bb8-46bc-9c19-435a63e13aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e17521-ead8-4f3f-a78a-818811e720e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84781d65-d860-4919-a820-81152e2e829f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
