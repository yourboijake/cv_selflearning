{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "267cdf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('xpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc0ec420",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to PyTorch Tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # Normalize pixel values\n",
    "])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9952ac7f",
   "metadata": {},
   "source": [
    "### Simple Auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e8271ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "256  / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f22e97aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters:  1146512\n"
     ]
    }
   ],
   "source": [
    "class MnistAutoEncoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MnistAutoEncoder, self).__init__()\n",
    "    self.encoder = nn.Sequential(\n",
    "      nn.Linear(in_features=784, out_features=512, bias=True),\n",
    "      nn.LayerNorm(512),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(in_features=512, out_features=256, bias=True),\n",
    "      nn.LayerNorm(256),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(in_features=256, out_features=128, bias=True),\n",
    "      nn.LayerNorm(128),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(in_features=128, out_features=32, bias=True),\n",
    "      nn.LayerNorm(32),\n",
    "      nn.ReLU(),\n",
    "    )\n",
    "    self.decoder = nn.Sequential(\n",
    "      nn.Linear(in_features=32, out_features=128, bias=True),\n",
    "      nn.LayerNorm(128),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(in_features=128, out_features=256, bias=True),\n",
    "      nn.LayerNorm(256),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(in_features=256, out_features=512, bias=True),\n",
    "      nn.LayerNorm(512),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(in_features=512, out_features=784, bias=True),\n",
    "      nn.LayerNorm(784),\n",
    "      nn.ReLU(),\n",
    "    )\n",
    "  \n",
    "  def forward(self, X):\n",
    "    X_embed = self.encoder(X)\n",
    "    X_restored = self.decoder(X_embed)\n",
    "    return X_embed, X_restored\n",
    "  \n",
    "\n",
    "mae = MnistAutoEncoder()\n",
    "mae.to(device)\n",
    "print('number of parameters: ', sum([p.numel() for p in mae.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7371c3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, batch 0: loss = 1.492504358291626\n",
      "epoch 0, batch 400: loss = 0.7581777572631836\n",
      "epoch 0, batch 800: loss = 0.7430914640426636\n",
      "epoch 1, batch 0: loss = 0.7466987371444702\n",
      "epoch 1, batch 400: loss = 0.6881937980651855\n",
      "epoch 1, batch 800: loss = 0.6563748717308044\n",
      "epoch 2, batch 0: loss = 0.656299352645874\n",
      "epoch 2, batch 400: loss = 0.6139695644378662\n",
      "epoch 2, batch 800: loss = 0.6040909886360168\n",
      "epoch 3, batch 0: loss = 0.5591377019882202\n",
      "epoch 3, batch 400: loss = 0.5295407176017761\n",
      "epoch 3, batch 800: loss = 0.5612890720367432\n",
      "epoch 4, batch 0: loss = 0.5158297419548035\n",
      "epoch 4, batch 400: loss = 0.4893154799938202\n",
      "epoch 4, batch 800: loss = 0.49156373739242554\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "optimizer = optim.SGD(mae.parameters(), lr=lr, weight_decay=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#training loop\n",
    "for epoch in range(5):\n",
    "  for batch_idx, batch in enumerate(train_loader):\n",
    "    X, y = batch\n",
    "    X = X.flatten(start_dim=1)\n",
    "    X = X.to(device)\n",
    "    batch_emb, batch_restored = mae(X)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(batch_restored, X)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch_idx % 400 == 0:\n",
    "      print(f'epoch {epoch}, batch {batch_idx}: loss = {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_cos_similarity(model, sampling_dataloader):\n",
    "  x, y = next(iter(sampling_dataloader))\n",
    "  x = x.flatten(start_dim=1)\n",
    "  x, y = x.to(device), y.to(device)\n",
    "  x_emb, _ = model(x)\n",
    "  x_emb_norm = F.normalize(x_emb, p=2.0, dim=1)\n",
    "  cos_sim = x_emb_norm @ x_emb_norm.T\n",
    "  cos_sim = cos_sim.cpu()\n",
    "  y_cpu = y.cpu()\n",
    "\n",
    "  print('class    |  same class  |  diff class  |  ratio (same / diff)')\n",
    "  print('-------------------------------------------------------------')\n",
    "  for label in set(y_cpu.numpy()):\n",
    "    idxs = (y_cpu == label).nonzero().squeeze(1)\n",
    "    not_idxs = (y_cpu != label).nonzero().squeeze(1)\n",
    "    mean_dot_prod_sharedclass = cos_sim[idxs][:, idxs].mean()\n",
    "    mean_dot_prod_diffclass = cos_sim[idxs][:, not_idxs].mean()\n",
    "    ratio = mean_dot_prod_sharedclass / mean_dot_prod_diffclass\n",
    "    print(f'class {label}        {mean_dot_prod_sharedclass:.2f}           {mean_dot_prod_diffclass:.2f}          {ratio:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9a8b3f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class    |  same class  |  diff class  |  ratio (same / diff)\n",
      "-------------------------------------------------------------\n",
      "class 0        0.93           0.87          1.07\n",
      "class 1        0.98           0.90          1.09\n",
      "class 2        0.94           0.91          1.03\n",
      "class 3        0.95           0.91          1.04\n",
      "class 4        0.95           0.91          1.04\n",
      "class 5        0.94           0.92          1.03\n",
      "class 6        0.95           0.92          1.04\n",
      "class 7        0.95           0.91          1.04\n",
      "class 8        0.96           0.93          1.03\n",
      "class 9        0.96           0.92          1.04\n"
     ]
    }
   ],
   "source": [
    "compare_cos_similarity(mae, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
