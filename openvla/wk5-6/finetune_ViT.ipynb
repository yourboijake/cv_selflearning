{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ba851e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('xpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab9e2698",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "resnet18.to(device)\n",
    "for param in resnet18.parameters(): #set requires grad to false: not training\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72d28ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "952a69b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "224",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#create dataset with pytorch datset and dataloaders\u001b[39;00m\n\u001b[32m      2\u001b[39m transform = torchvision.transforms.Compose(\n\u001b[32m      3\u001b[39m   torchvision.transforms.ToTensor(),\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m   \u001b[43mtorchvision\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[32m      5\u001b[39m   torchvision.transforms.Normalize(mean=[\u001b[32m0.485\u001b[39m, \u001b[32m0.456\u001b[39m, \u001b[32m0.406\u001b[39m], std=[\u001b[32m0.229\u001b[39m, \u001b[32m0.224\u001b[39m, \u001b[32m0.225\u001b[39m])  \u001b[38;5;66;03m# ImageNet normalization\u001b[39;00m\n\u001b[32m      6\u001b[39m )\n\u001b[32m      7\u001b[39m TRAIN_BATCH_SIZE = \u001b[32m128\u001b[39m\n\u001b[32m      9\u001b[39m trainset = torchvision.datasets.CIFAR10(\n\u001b[32m     10\u001b[39m     root=\u001b[33m'\u001b[39m\u001b[33m./data\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     11\u001b[39m     train=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     12\u001b[39m     download=\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m     13\u001b[39m     transform=transform,\n\u001b[32m     14\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming/learning/ml/cv_selflearning/.venv/lib/python3.12/site-packages/torchvision/transforms/transforms.py:341\u001b[39m, in \u001b[36mResize.__init__\u001b[39m\u001b[34m(self, size, interpolation, max_size, antialias)\u001b[39m\n\u001b[32m    338\u001b[39m \u001b[38;5;28mself\u001b[39m.max_size = max_size\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(interpolation, \u001b[38;5;28mint\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     interpolation = \u001b[43m_interpolation_modes_from_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[38;5;28mself\u001b[39m.interpolation = interpolation\n\u001b[32m    344\u001b[39m \u001b[38;5;28mself\u001b[39m.antialias = antialias\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/programming/learning/ml/cv_selflearning/.venv/lib/python3.12/site-packages/torchvision/transforms/functional.py:50\u001b[39m, in \u001b[36m_interpolation_modes_from_int\u001b[39m\u001b[34m(i)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_interpolation_modes_from_int\u001b[39m(i: \u001b[38;5;28mint\u001b[39m) -> InterpolationMode:\n\u001b[32m     42\u001b[39m     inverse_modes_mapping = {\n\u001b[32m     43\u001b[39m         \u001b[32m0\u001b[39m: InterpolationMode.NEAREST,\n\u001b[32m     44\u001b[39m         \u001b[32m2\u001b[39m: InterpolationMode.BILINEAR,\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m         \u001b[32m1\u001b[39m: InterpolationMode.LANCZOS,\n\u001b[32m     49\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minverse_modes_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mKeyError\u001b[39m: 224"
     ]
    }
   ],
   "source": [
    "#create dataset with pytorch datset and dataloaders\n",
    "transform = torchvision.transforms.Compose(\n",
    "  torchvision.transforms.ToTensor(),\n",
    "  torchvision.transforms.Resize(224, 224),\n",
    "  torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    ")\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', \n",
    "    train=True,\n",
    "    download=True, \n",
    "    transform=transform,\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, \n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', \n",
    "    train=False,\n",
    "    download=True, \n",
    "    transform=transform,\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, \n",
    "    batch_size=200,\n",
    "    shuffle=False, \n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f8059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of classification\n",
    "def eval_model(model, testloader, device):\n",
    "  acc_list = []\n",
    "  denom = 0\n",
    "  for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    out = model(inputs)\n",
    "    preds = out.argmax(dim=-1)\n",
    "    acc = preds.eq(labels).sum()\n",
    "    denom += inputs.shape[0]\n",
    "    acc_list.append(acc)\n",
    "  return sum(acc_list) / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31f9a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace final output layer of resnet18 with a new linear layer, out_features=10 for CIFAR10\n",
    "\n",
    "in_features = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(in_features, 10, bias=False) #new classification projection\n",
    "resnet18.fc.weight.requires_grad = True #ensure requires grad is set to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f315d58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3781, device='xpu:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the initial model's perf on cifar10 test set\n",
    "eval_model(resnet18, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47563061",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params=resnet18.fc.parameters(), lr=0.002, weight_decay=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c7806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, batch 99: loss = 1.6583102941513062\n",
      "epoch 0, batch 299: loss = 1.508906364440918\n",
      "test accuracy:  0.4423999786376953 \n",
      "\n",
      "epoch 1, batch 99: loss = 1.5073816776275635\n",
      "epoch 1, batch 299: loss = 1.6249878406524658\n",
      "test accuracy:  0.45319998264312744 \n",
      "\n",
      "epoch 2, batch 99: loss = 1.5966134071350098\n",
      "epoch 2, batch 299: loss = 1.5739390850067139\n",
      "test accuracy:  0.4372999966144562 \n",
      "\n",
      "epoch 3, batch 99: loss = 1.6781584024429321\n",
      "epoch 3, batch 299: loss = 1.7415069341659546\n",
      "test accuracy:  0.4412999749183655 \n",
      "\n",
      "epoch 4, batch 99: loss = 1.503389835357666\n",
      "epoch 4, batch 299: loss = 1.4510746002197266\n",
      "test accuracy:  0.4481000006198883 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "  resnet18.train()\n",
    "  for i, data in enumerate(trainloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = resnet18(inputs)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 200 == 99:\n",
    "      print(f'epoch {epoch}, batch {i}: loss = {loss.item()}')\n",
    "\n",
    "  #eval model at end of epoch\n",
    "  resnet18.eval()\n",
    "  acc = eval_model(resnet18, testloader, device).item()\n",
    "  print('test accuracy: ', acc, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
